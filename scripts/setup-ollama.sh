#!/bin/bash

# Setup script for Ollama in Docker container
echo "ğŸ¤– Setting up Ollama AI models..."

# Wait for Ollama service to be ready
echo "â³ Waiting for Ollama service to start..."
while ! curl -s http://localhost:11434/api/tags > /dev/null; do
    echo "   Ollama not ready yet, waiting 5 seconds..."
    sleep 5
done

echo "âœ… Ollama service is ready!"

# Pull required models
echo "ğŸ“¥ Pulling Llama 3.1 8B model (this may take several minutes)..."
docker exec verdict360-ollama ollama pull llama3.1:8b

# Verify model is available
echo "ğŸ” Verifying model installation..."
if docker exec verdict360-ollama ollama list | grep -q "llama3.1:8b"; then
    echo "âœ… Llama 3.1 8B model installed successfully!"
else
    echo "âŒ Failed to install Llama model"
    exit 1
fi

# Test model with a simple query
echo "ğŸ§ª Testing model with a simple legal question..."
docker exec verdict360-ollama ollama run llama3.1:8b "What is the legal age of majority in South Africa? Please provide a brief answer."

echo "ğŸ‰ Ollama setup complete!"